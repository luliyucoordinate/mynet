syntax = "proto3";

package mynet;

// Specifies the shape (dimensions) of a Tensor.
message TensorShape {
  repeated int64 dim = 1;
}

message TensorProto {
  // 4D dimensions -- deprecated.  Use "shape" instead.
  int32 num = 1;
  int32 channels = 2;
  int32 height = 3;
  int32 width = 4;

  repeated float data = 5;
  repeated float diff = 6;
  TensorShape shape = 7;
  repeated double double_data = 8;
  repeated double double_diff = 9;
}

// The TensorProtoVector is simply a way to pass multiple Tensorproto instances
// around.
message TensorProtoVector {
  repeated TensorProto Tensors = 1;
}

message NetParameter {
  string name = 1; // consider giving the network a name
  // DEPRECATED. See InputParameter. The input Tensors to the network.
  repeated string input = 3;
  // DEPRECATED. See InputParameter. The shape of the input Tensors.
  repeated TensorShape input_shape = 8;

  // 4D input dimensions -- deprecated.  Use "input_shape" instead.
  // If specified, for each input Tensor there should be four
  // values specifying the num, channels, height and width of the input Tensor.
  // Thus, there should be a total of (4 * #input) numbers.
  repeated int32 input_dim = 4;

  // Whether the network will force every layer to carry out backward operation.
  // If set False, then whether to carry out backward is determined
  // automatically according to the net structure and learning rates.
  bool force_backward = 5;

  // Print debugging information about results while running Net::Forward,
  // Net::Backward, and Net::Update.
  bool debug_info = 7;

  // The layers that make up the net.  Each of their configurations, including
  // connectivity and behavior, is specified as a LayerParameter.
  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.
}


// NOTE
// Update the next available ID when you add a new LayerParameter field.
//
// LayerParameter next available layer-specific ID: 149 (last added: clip_param)
message LayerParameter {
  string name = 1; // the layer name
  string type = 2; // the layer type
  repeated string bottom = 3; // the name of each bottom Tensor
  repeated string top = 4; // the name of each top Tensor

  // The amount of weight to assign each top Tensor in the objective.
  // Each layer assigns a default value, usually of either 0 or 1,
  // to each top Tensor.
  repeated float loss_weight = 5;

  // The Tensors containing the numeric parameters of the layer.
  repeated TensorProto Tensors = 7;

  ConvolutionParameter convolution_param = 106;
}

message ConvolutionParameter {
  uint32 num_output = 1; // The number of outputs for the layer
  bool bias_term = 2; // whether to have bias terms

  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in all spatial dimensions, or once per spatial dimension.
  repeated uint32 pad = 3; // The padding size; defaults to 0
  repeated uint32 kernel_size = 4; // The kernel size
  repeated uint32 stride = 6; // The stride; defaults to 1
  // Factor used to dilate the kernel, (implicitly) zero-filling the resulting
  // holes. (Kernel dilation is sometimes referred to by its use in the
  // algorithme Ã  trous from Holschneider et al. 1987.)
  repeated uint32 dilation = 18; // The dilation; defaults to 1

  // For 2D convolution only, the *_h and *_w versions may also be used to
  // specify both spatial dimensions.
  uint32 pad_h = 9; // The padding height (2D only)
  uint32 pad_w = 10; // The padding width (2D only)
  uint32 kernel_h = 11; // The kernel height (2D only)
  uint32 kernel_w = 12; // The kernel width (2D only)
  uint32 stride_h = 13; // The stride height (2D only)
  uint32 stride_w = 14; // The stride width (2D only)

  uint32 group = 5; // The group size for group conv

  // The axis to interpret as "channels" when performing convolution.
  // Preceding dimensions are treated as independent inputs;
  // succeeding dimensions are treated as "spatial".
  // With (N, C, H, W) inputs, and axis == 1 (the default), we perform
  // N independent 2D convolutions, sliding C-channel (or (C/g)-channels, for
  // groups g>1) filters across the spatial axes (H, W) of the input.
  // With (N, C, D, H, W) inputs, and axis == 1, we perform
  // N independent 3D convolutions, sliding (C/g)-channels
  // filters across the spatial axes (D, H, W) of the input.
  int32 axis = 16;

  // Whether to force use of the general ND convolution, even if a specific
  // implementation for blobs of the appropriate number of spatial dimensions
  // is available. (Currently, there is only a 2D-specific convolution
  // implementation; for input blobs with num_axes != 2, this option is
  // ignored and the ND implementation will be used.)
  bool force_nd_im2col = 17;
}

message FillerParameter {
  // The filler type.
 string type = 1;
 float value = 2; // the value in constant filler
 float min = 3; // the min value in uniform filler
 float max = 4; // the max value in uniform filler
 float mean = 5; // the mean value in Gaussian filler
 float std = 6; // the std value in Gaussian filler
  // The expected number of non-zero output weights for a given input in
  // Gaussian filler -- the default -1 means don't perform sparsification.
 int32 sparse = 7;
  // Normalize the filler variance by fan_in, fan_out, or their average.
  // Applies to 'xavier' and 'msra' fillers.
  enum VarianceNorm {
    FAN_IN = 0;
    FAN_OUT = 1;
    AVERAGE = 2;
  }
 VarianceNorm variance_norm = 8;
}